{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "#nltk models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, balanced_accuracy_score, cohen_kappa_score, roc_auc_score\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "#classifiers\n",
    "import sklearn\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout, Dense, Flatten, Embedding,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D \n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from sklearn.svm import LinearSVC\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>AC/Heater</th>\n",
       "      <th>L2 AC/Heater</th>\n",
       "      <th>Check-in Experience</th>\n",
       "      <th>L2 Check-in Experience</th>\n",
       "      <th>Comfort &amp; Safety</th>\n",
       "      <th>L2 Comfort &amp; Safety</th>\n",
       "      <th>Food Experience</th>\n",
       "      <th>L2 Food Experience</th>\n",
       "      <th>Hotel Infrastructure</th>\n",
       "      <th>...</th>\n",
       "      <th>L2 Hygiene &amp; Cleanliness</th>\n",
       "      <th>Room Equipment &amp; Amenities</th>\n",
       "      <th>L2 Room Equipment &amp; Amenities</th>\n",
       "      <th>Staff &amp; Service</th>\n",
       "      <th>L2 Staff &amp; Service</th>\n",
       "      <th>TV &amp; WiFi</th>\n",
       "      <th>L2 TV &amp; WiFi</th>\n",
       "      <th>Washroom</th>\n",
       "      <th>L2 Washroom</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quiet friendly staff and spacious room. housek...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stayed at this hotel a few times and always ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We were planning a really late check in, so I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Renovating rooms right now . good beds and nic...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overall I'd give it 4 stars, newly remodeled r...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  AC/Heater  L2 AC/Heater  \\\n",
       "0  quiet friendly staff and spacious room. housek...          0             4   \n",
       "1  Stayed at this hotel a few times and always ta...          0             4   \n",
       "2  We were planning a really late check in, so I ...          0             4   \n",
       "3  Renovating rooms right now . good beds and nic...          0             4   \n",
       "4  Overall I'd give it 4 stars, newly remodeled r...          0             4   \n",
       "\n",
       "   Check-in Experience  L2 Check-in Experience  Comfort & Safety  \\\n",
       "0                    0                       5                 0   \n",
       "1                    1                       0                 0   \n",
       "2                    0                       5                 0   \n",
       "3                    0                       5                 0   \n",
       "4                    0                       5                 0   \n",
       "\n",
       "   L2 Comfort & Safety  Food Experience  L2 Food Experience  \\\n",
       "0                    6                0                   6   \n",
       "1                    6                0                   6   \n",
       "2                    6                0                   6   \n",
       "3                    6                0                   6   \n",
       "4                    6                0                   6   \n",
       "\n",
       "   Hotel Infrastructure  ...  L2 Hygiene & Cleanliness  \\\n",
       "0                     0  ...                         5   \n",
       "1                     0  ...                         5   \n",
       "2                     0  ...                         5   \n",
       "3                     0  ...                         5   \n",
       "4                     0  ...                         5   \n",
       "\n",
       "   Room Equipment & Amenities  L2 Room Equipment & Amenities  Staff & Service  \\\n",
       "0                           0                              5                0   \n",
       "1                           0                              5                0   \n",
       "2                           0                              5                0   \n",
       "3                           0                              5                0   \n",
       "4                           0                              5                0   \n",
       "\n",
       "   L2 Staff & Service  TV & WiFi  L2 TV & WiFi  Washroom  L2 Washroom  \\\n",
       "0                   4          0             7         0            8   \n",
       "1                   4          0             7         0            8   \n",
       "2                   4          0             7         0            8   \n",
       "3                   4          0             7         0            8   \n",
       "4                   4          0             7         0            8   \n",
       "\n",
       "   Unnamed: 21  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\oyo\\Desktop')\n",
    "df = pd.read_excel(r'data_set.xlsx',encoding = 'ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for L1\n",
    "stemmer2 = SnowballStemmer('english')\n",
    "## preprocessing text:\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filter_SW = {\"very\",\"until\",\"out\",\"than\",'ain','against','aren',\"aren't\",\"arent\",'couldn',\"couldn't\",\"couldnt\",\"didn\",\"didn't\",\"didnt\",\"doesn\",\"doesn't\",\"doesnt\",\"don\",\"don't\",\"dont\",\"hadn\",\"hadn't\",\"hadnt\",\"hasn\",\"hasn't\",\"haven\",\"haven't\",\"hasnt\",\"isn\",\"isn't\",\"isnt\",\"mightn't\",\"mightnt\",\"mightn\",\"mustn\",\"mustn't\",\"mustnt\",\"needn\",\"needn't\",\"neednt\",\"no\",\"not\",\"nor\",\"off\",\"shan\",\"shan't\",\"shant\",\"shouldn\",\"shouldn't\",\"shouldnt\",\"wasn't\",\"wasnt\",\"wasn\",\"weren\",\"weren't\",\"werent\",\"won't\",\"wont\",\"won\",\"wouldn\",\"wouldn't\",\"wouldnt\"}\n",
    "Nstop_words = stop_words - filter_SW\n",
    "Nstop_words.update([\"'\",\"' \",\" '\",\"â€™\",\" â€™\",\"â€™ \"])\n",
    "punct = \"\"\n",
    "for i in string.punctuation:\n",
    "    if(i!=\"'\" ):\n",
    "        punct = punct+i\n",
    "#print(punct)\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "def preprocessing_text(text,lemma=True):\n",
    "    text = text.lower()\n",
    "    #replacing apostrophe with none\n",
    "    text = text.replace(\"â€™\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace('/','')\n",
    "    #replacing special characters with a space\n",
    "    text = re.sub('[^A-Za-z]+', \" \", text)\n",
    "    \n",
    "    #replacing newline,tabs with none\n",
    "    text = re.sub(r\"[\\n\\t]*\", \"\", text)\n",
    "    \n",
    "    #removing multiple sapces\n",
    "    text = re.sub(\" +\",\" \", text)\n",
    "    \n",
    "    #removing punctuations except apostrophe\n",
    "    text = [word.strip(punct) for word in text.split(\" \")]\n",
    "    \n",
    "    # remove words that contain numbers\n",
    "    #text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    \n",
    "    #removing stopwords\n",
    "    text = [x for x in text if x not in Nstop_words]\n",
    "    \n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    \n",
    "    # lemmatize text\n",
    "    if lemma==True:\n",
    "        pos_tags = pos_tag(text)\n",
    "        text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "        \n",
    "    else:\n",
    "        ps = PorterStemmer()\n",
    "        text =  [stemmer2.stem(word) for word in text]\n",
    "        \n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem=[]\n",
    "for i in range(len(df)):\n",
    "    t=preprocessing_text(str(df['Review'][i]),lemma=False)#false for stemming and true for lemmatization\n",
    "    stem.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence padding\n",
    "\n",
    "tokenizer = Tokenizer(num_words= 2000)\n",
    "tokenizer.fit_on_texts(stem)\n",
    "sequences = tokenizer.texts_to_sequences(stem)\n",
    "seq = sequence.pad_sequences(sequences , maxlen = 60,padding = 'post', truncating = 'post' )\n",
    "#print(tokenizer.word_counts)\n",
    "#print(\"shape: \",np.shape(seq))\n",
    "#print(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\oyo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\oyo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 10)            20000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 58, 64)            1984      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 29, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 27, 32)            6176      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 30,337\n",
      "Trainable params: 30,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#creating the model\n",
    "reshape = keras.layers.Reshape\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = 2000, output_dim = 10 , input_length = 60))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(64,kernel_size=3, strides = 1,activation='relu', padding = 'valid'))\n",
    "model.add(MaxPooling1D(pool_size = 2, padding = 'same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "#importing text file\n",
    "Data = pd.read_excel(r'test_set.xlsx', encoding = 'ISO-8859-1')\n",
    "#removing highly positive comments\n",
    "model = SentimentIntensityAnalyzer()\n",
    "sentiment = pd.DataFrame(columns=['neg','neu','pos','compound'])\n",
    "for i in range(len(Data)):\n",
    "    \n",
    "    sentence = Data['Review'][i]\n",
    "    sentence = str(sentence)\n",
    "    ss = model.polarity_scores(sentence)\n",
    "    sentiment =  sentiment.append(ss , ignore_index = True)\n",
    "DF = pd.concat([Data,sentiment], axis = 1)\n",
    "DF['sentiment']=DF['compound'].apply(lambda x: 0  if x<0.9 else np.nan )\n",
    "#result.head(10)\n",
    "nan_rows = DF[DF['sentiment'].isnull()].index.values\n",
    "DF = DF.drop(nan_rows)\n",
    "DF.reset_index()\n",
    "print(len(DF))\n",
    "print(len(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequnce padding of test file\n",
    "com=[]\n",
    "for i in range(len(DF)):\n",
    "    t=preprocessing_text(DF['Review'][i], lemma = False)\n",
    "    com.append(t)\n",
    "seqcs = tokenizer.texts_to_sequences(com)\n",
    "seq1 = sequence.pad_sequences(seqcs , maxlen = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>AC/Heater_Predict</th>\n",
       "      <th>Check-in Experience_Predict</th>\n",
       "      <th>Comfort &amp; Safety_Predict</th>\n",
       "      <th>Food Experience_Predict</th>\n",
       "      <th>Hotel Infrastructure_Predict</th>\n",
       "      <th>Hygiene &amp; Cleanliness_Predict</th>\n",
       "      <th>Room Equipment &amp; Amenities_Predict</th>\n",
       "      <th>Staff &amp; Service_Predict</th>\n",
       "      <th>TV &amp; WiFi_Predict</th>\n",
       "      <th>Washroom_Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good location</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THA HOYEL IS NEW UNDRER WORKING BUT EXLENT FRE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROOM NEAT AND CLEAN BUT WATER IS NOT GOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad experience. No hotwater. Breakfast not ser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>room quality is not good. good for couples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review AC/Heater_Predict  \\\n",
       "0                                      good location               NaN   \n",
       "1  THA HOYEL IS NEW UNDRER WORKING BUT EXLENT FRE...               NaN   \n",
       "2          ROOM NEAT AND CLEAN BUT WATER IS NOT GOOD               NaN   \n",
       "3  Bad experience. No hotwater. Breakfast not ser...               NaN   \n",
       "4         room quality is not good. good for couples               NaN   \n",
       "\n",
       "  Check-in Experience_Predict Comfort & Safety_Predict  \\\n",
       "0                         NaN                      NaN   \n",
       "1                         NaN                      NaN   \n",
       "2                         NaN                      NaN   \n",
       "3                         NaN                      NaN   \n",
       "4                         NaN                      NaN   \n",
       "\n",
       "  Food Experience_Predict Hotel Infrastructure_Predict  \\\n",
       "0                     NaN                          NaN   \n",
       "1                     NaN                          NaN   \n",
       "2                     NaN                          NaN   \n",
       "3                     NaN                          NaN   \n",
       "4                     NaN                          NaN   \n",
       "\n",
       "  Hygiene & Cleanliness_Predict Room Equipment & Amenities_Predict  \\\n",
       "0                           NaN                                NaN   \n",
       "1                           NaN                                NaN   \n",
       "2                           NaN                                NaN   \n",
       "3                           NaN                                NaN   \n",
       "4                           NaN                                NaN   \n",
       "\n",
       "  Staff & Service_Predict TV & WiFi_Predict Washroom_Predict  \n",
       "0                     NaN               NaN              NaN  \n",
       "1                     NaN               NaN              NaN  \n",
       "2                     NaN               NaN              NaN  \n",
       "3                     NaN               NaN              NaN  \n",
       "4                     NaN               NaN              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the output file of L1 tagging\n",
    "out=pd.DataFrame(columns=['AC/Heater_Predict','Check-in Experience_Predict', 'Comfort & Safety_Predict', 'Food Experience_Predict', 'Hotel Infrastructure_Predict','Hygiene & Cleanliness_Predict','Room Equipment & Amenities_Predict','Staff & Service_Predict','TV & WiFi_Predict','Washroom_Predict'])\n",
    "output_L1 = pd.concat([DF, out], axis=1)\n",
    "output_L1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------AC/Heater-------\n",
      "WARNING:tensorflow:From C:\\Users\\oyo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\oyo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 16623 samples, validate on 1446 samples\n",
      "Epoch 1/5\n",
      "16623/16623 [==============================] - 5s 293us/step - loss: 0.1889 - acc: 0.9586 - val_loss: 0.1344 - val_acc: 0.9703\n",
      "Epoch 2/5\n",
      "16623/16623 [==============================] - 4s 270us/step - loss: 0.1403 - acc: 0.9626 - val_loss: 0.0767 - val_acc: 0.9730\n",
      "Epoch 3/5\n",
      "16623/16623 [==============================] - 4s 248us/step - loss: 0.0694 - acc: 0.9735 - val_loss: 0.0635 - val_acc: 0.9765\n",
      "Epoch 4/5\n",
      "16623/16623 [==============================] - 4s 267us/step - loss: 0.0530 - acc: 0.9795 - val_loss: 0.0613 - val_acc: 0.9758\n",
      "Epoch 5/5\n",
      "16623/16623 [==============================] - 4s 265us/step - loss: 0.0425 - acc: 0.9847 - val_loss: 0.0658 - val_acc: 0.9786\n",
      "Accuracy score of L1:  0.9747634069400631 \n",
      "roc_auc score of L1 model:0.9511835268458528 \n",
      "[[908   9]\n",
      " [ 15  19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       917\n",
      "           1       0.68      0.56      0.61        34\n",
      "\n",
      "    accuracy                           0.97       951\n",
      "   macro avg       0.83      0.77      0.80       951\n",
      "weighted avg       0.97      0.97      0.97       951\n",
      "\n",
      "-------Check-in Experience-------\n",
      "Train on 16623 samples, validate on 1446 samples\n",
      "Epoch 1/5\n",
      "16623/16623 [==============================] - 4s 245us/step - loss: 0.1318 - acc: 0.9653 - val_loss: 0.1030 - val_acc: 0.9682\n",
      "Epoch 2/5\n",
      "16623/16623 [==============================] - 4s 264us/step - loss: 0.0925 - acc: 0.9678 - val_loss: 0.0983 - val_acc: 0.9682\n",
      "Epoch 3/5\n",
      "16623/16623 [==============================] - 4s 245us/step - loss: 0.0745 - acc: 0.9718 - val_loss: 0.1055 - val_acc: 0.9654\n",
      "Epoch 4/5\n",
      "16623/16623 [==============================] - 4s 264us/step - loss: 0.0613 - acc: 0.9760 - val_loss: 0.1056 - val_acc: 0.9703\n",
      "Epoch 5/5\n",
      "16623/16623 [==============================] - 4s 253us/step - loss: 0.0477 - acc: 0.9818 - val_loss: 0.1254 - val_acc: 0.9661\n",
      "Accuracy score of L1:  0.9631966351209253 \n",
      "roc_auc score of L1 model:0.8008421709295072 \n",
      "[[907   9]\n",
      " [ 26   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       916\n",
      "           1       0.50      0.26      0.34        35\n",
      "\n",
      "    accuracy                           0.96       951\n",
      "   macro avg       0.74      0.62      0.66       951\n",
      "weighted avg       0.95      0.96      0.96       951\n",
      "\n",
      "-------Comfort & Safety-------\n",
      "Train on 16623 samples, validate on 1446 samples\n",
      "Epoch 1/5\n",
      "16623/16623 [==============================] - 4s 231us/step - loss: 0.2828 - acc: 0.9008 - val_loss: 0.2111 - val_acc: 0.9232\n",
      "Epoch 2/5\n",
      "16623/16623 [==============================] - 4s 248us/step - loss: 0.1778 - acc: 0.9311 - val_loss: 0.1622 - val_acc: 0.9391\n",
      "Epoch 3/5\n",
      "16623/16623 [==============================] - 4s 250us/step - loss: 0.1505 - acc: 0.9403 - val_loss: 0.1587 - val_acc: 0.9419\n",
      "Epoch 4/5\n",
      "16623/16623 [==============================] - 4s 237us/step - loss: 0.1377 - acc: 0.9454 - val_loss: 0.1634 - val_acc: 0.9364\n",
      "Epoch 5/5\n",
      " 6560/16623 [==========>...................] - ETA: 2s - loss: 0.1289 - acc: 0.9488"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-385042c4684f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.08\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#predicting results for test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#add other classes\n",
    "dict_labels={'y1':'AC/Heater',\n",
    "'y2':'Check-in Experience',\n",
    "'y3':'Comfort & Safety',\n",
    "'y4':'Food Experience',\n",
    "'y5':'Hotel Infrastructure',\n",
    "'y6':'Hygiene & Cleanliness',\n",
    "'y7':'Room Equipment & Amenities',\n",
    "'y8':'Staff & Service',\n",
    "'y9':'TV & WiFi',\n",
    "'y10':'Washroom',\n",
    "}\n",
    "\n",
    "dict_labels2={'y1':'AC/Heater_Predict',\n",
    "'y2':'Check-in Experience_Predict',\n",
    "'y3':'Comfort & Safety_Predict',\n",
    "'y4':'Food Experience_Predict',\n",
    "'y5':'Hotel Infrastructure_Predict',\n",
    "'y6':'Hygiene & Cleanliness_Predict',\n",
    "'y7':'Room Equipment & Amenities_Predict',\n",
    "'y8':'Staff & Service_Predict',\n",
    "'y9':'TV & WiFi_Predict',\n",
    "'y10':'Washroom_Predict',\n",
    "}\n",
    "\n",
    "for i in dict_labels:\n",
    "    print(\"-------\"+dict_labels[i]+\"-------\")\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(seq,df[dict_labels[i]], test_size = 0.05)\n",
    "    x_train,x_val,y_train,y_val = train_test_split(X_train,Y_train,test_size=0.08)\n",
    "    model.fit(x_train, y_train,batch_size = 32, validation_data=(x_val, y_val), class_weight = 'balanced', epochs=5)\n",
    "    #predicting results for test set\n",
    "    x_test = seq1\n",
    "    y_sc1= model.predict(x_test)\n",
    "    y_score1 = np.zeros(len(y_sc1))\n",
    "    for j in range(len(y_score1)):\n",
    "        if y_sc1[j] <= 0.51:\n",
    "            y_score1[j] = 0\n",
    "        else:\n",
    "            y_score1[j] = 1\n",
    "    output_L1[dict_labels2[i]] = y_score1\n",
    "    \n",
    "    #calculating accuracy with standard probability distribution\n",
    "    y_sc = model.predict(X_test)\n",
    "    y_score = np.zeros(len(y_sc))\n",
    "    for i in range(len(y_sc)):\n",
    "        if y_sc[i] < 0.51:\n",
    "            y_score[i] = 0\n",
    "        else:\n",
    "            y_score[i] = 1\n",
    "            \n",
    "    \n",
    "    print(\"Accuracy score of L1:  {} \" .format(str(accuracy_score(Y_test,y_score))))\n",
    "    print(\"roc_auc score of L1 model:{} \".format(str(roc_auc_score(Y_test, y_sc))))\n",
    "    print(confusion_matrix(Y_test,y_score))  \n",
    "    print(classification_report(Y_test,y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_L1.reset_index()\n",
    "output_L1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_Vector = TfidfVectorizer(max_features=2000, min_df=0.001, max_df=0.5,stop_words=Nstop_words,ngram_range = (1,4))\n",
    "#x = t_Vector.fit_transform(stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = df[['L2 AC/Heater', 'L2 Check-in Experience',\n",
    "       'L2 Comfort & Safety', 'L2 Food Experience', 'L2 Hotel Infrastructure',\n",
    "       'L2 Hygiene & Cleanliness', 'L2 Room Equipment & Amenities', 'L2 Staff & Service',\n",
    "       'L2 TV & WiFi', 'L2 Washroom']]\n",
    "dict_labels = {'y1':'L2 AC/Heater',\n",
    "'y2':'L2 Check-in Experience',\n",
    "'y3':'L2 Comfort & Safety',\n",
    "'y4':'L2 Food Experience',\n",
    "'y5':'L2 Hotel Infrastructure',\n",
    "'y6':'L2 Hygiene & Cleanliness',\n",
    "'y7':'L2 Room Equipment & Amenities',\n",
    "'y8':'L2 Staff & Service',\n",
    "'y9':'L2 TV & WiFi',\n",
    "'y10':'L2 Washroom',\n",
    "}\n",
    "for i in dict_labels:\n",
    "    text = df_cols[dict_labels[i]]\n",
    "    encode = LabelEncoder()\n",
    "    df[dict_labels[i]] = encode.fit_transform(text.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outt=pd.DataFrame(columns=['L2 AC/Heater predict','L2 Check-in Experience predict', 'L2 Comfort & Safety predict', 'L2 Food Experience predict', 'L2 Hotel Infrastructure predict','L2 Hygiene & Cleanliness predict','L2 Room Equipment & Amenities predict','L2 Staff & Service predict','L2 TV & WiFi predict','L2 Washroom predict'])\n",
    "final = pd.concat([output_L1, outt], axis=1)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictions for L2 using rbf kernel svm\n",
    "dict_labels_L1 = {'y1':'AC/Heater',\n",
    "'y2':'Check-in Experience',\n",
    "'y3':'Comfort & Safety',\n",
    "'y4':'Food Experience',\n",
    "'y5':'Hotel Infrastructure',\n",
    "'y6':'Hygiene & Cleanliness',\n",
    "'y7':'Room Equipment & Amenities',\n",
    "'y8':'Staff & Service',\n",
    "'y9':'TV & WiFi',\n",
    "'y10':'Washroom',\n",
    "}\n",
    "dict_labels_L2 = {'y1':'L2 AC/Heater',\n",
    "'y2':'L2 Check-in Experience',\n",
    "'y3':'L2 Comfort & Safety',\n",
    "'y4':'L2 Food Experience',\n",
    "'y5':'L2 Hotel Infrastructure',\n",
    "'y6':'L2 Hygiene & Cleanliness',\n",
    "'y7':'L2 Room Equipment & Amenities',\n",
    "'y8':'L2 Staff & Service',\n",
    "'y9':'L2 TV & WiFi',\n",
    "'y10':'L2 Washroom',\n",
    "}\n",
    "dict_labels2={'y1':'AC/Heater_Predict',\n",
    "'y2':'Check-in Experience_Predict',\n",
    "'y3':'Comfort & Safety_Predict',\n",
    "'y4':'Food Experience_Predict',\n",
    "'y5':'Hotel Infrastructure_Predict',\n",
    "'y6':'Hygiene & Cleanliness_Predict',\n",
    "'y7':'Room Equipment & Amenities_Predict',\n",
    "'y8':'Staff & Service_Predict',\n",
    "'y9':'TV & WiFi_Predict',\n",
    "'y10':'Washroom_Predict',\n",
    "}\n",
    "dict_labels_L3 = {'y1':'L2 AC/Heater predict',\n",
    "'y2':'L2 Check-in Experience predict',\n",
    "'y3':'L2 Comfort & Safety predict',\n",
    "'y4':'L2 Food Experience predict',\n",
    "'y5':'L2 Hotel Infrastructure predict',\n",
    "'y6':'L2 Hygiene & Cleanliness predict',\n",
    "'y7':'L2 Room Equipment & Amenities predict',\n",
    "'y8':'L2 Staff & Service predict',\n",
    "'y9':'L2 TV & WiFi predict',\n",
    "'y10':'L2 Washroom predict',\n",
    "}\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for i in dict_labels_L1:\n",
    "\n",
    "    print(\"-------\"+dict_labels_L1[i]+\"-------\")\n",
    "    df1  = pd.DataFrame()\n",
    "    DF1 = pd.DataFrame()\n",
    "    df1 = df1.append(df[df[dict_labels_L1[i]] == 1])\n",
    "    DF1 = DF1.append(final[final[dict_labels2[i]] == 1])\n",
    "    df1 = df1.reset_index()\n",
    "    DF1 = DF1.reset_index()\n",
    "    #print(len(DF1))\n",
    "    y = df1[dict_labels_L2[i]]\n",
    "    #y1 = DF1[dict_labels_L2[i]]\n",
    "    \n",
    "    #X,Y = nr.fit_sample(df1['Review'],y)\n",
    "    stem=[]\n",
    "    stem1 = []\n",
    "    for j in range(len(df1)):\n",
    "        t = str(df1['Review'][j])\n",
    "        t = preprocessing_text(t,lemma = False) \n",
    "        stem.append(t)\n",
    "        \n",
    "    if len(DF1) != 0:\n",
    "        for j in range(len(DF1)):\n",
    "            t1 = str(DF1['Review'][j])\n",
    "            t1 = preprocessing_text(t1, lemma = False)\n",
    "            stem1.append(t1)\n",
    "        '''\n",
    "        embeddings = embed(stem)\n",
    "        embeddings1 = embed(stem1)\n",
    "        config = tf.ConfigProto()\n",
    "        config.graph_options.rewrite_options.shape_optimization = 2\n",
    "        session = tf.Session(config=config)\n",
    "        sess = session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        x = session.run(embeddings)   \n",
    "        x1 = session.run(embeddings1)\n",
    "        '''\n",
    "        x = t_Vector.fit_transform(stem)\n",
    "        x_train,x_test,y_train,Y_test = train_test_split(x,y,test_size=0.15,random_state = 20)\n",
    "        model = RFE(RandomForestClassifier(max_features = 'auto', criterion = 'gini', bootstrap = True,class_weight = 'balanced'), 50, step=10)\n",
    "        model.fit(x_train,y_train)\n",
    "        x1 = t_Vector.transform(stem1)\n",
    "\n",
    "        '''\n",
    "        #x_test,Y_test = (x1,y1)\n",
    "        #clf = RandomForestClassifier(class_weight = 'balanced')\n",
    "        #svm = LinearSVC(multi_class = 'ovr' , class_weight = 'balanced' )\n",
    "        clf = SVC(kernel = 'rbf',class_weight = 'balanced', decision_function_shape = 'ovr', C = 1000000,gamma = 1e-06 )\n",
    "        #clf = CalibratedClassifierCV(svm)\n",
    "        clf.fit(x_train,y_train)\n",
    "        #model = MultinomialNB(alpha=1, class_prior=None, fit_prior=True).fit(x_train,y_train)\n",
    "        '''\n",
    "        y_score1 = model.predict(x1)\n",
    "        y_score = model.predict(x_test)\n",
    "        DF1[dict_labels_L3[i]] = y_score1 \n",
    "        result = result.append(DF1)\n",
    "\n",
    "        print(\"Balanced_accuracy score is {}\\n\".format(str(balanced_accuracy_score(Y_test, y_score))))\n",
    "        print(\"accuracy score: \", accuracy_score(Y_test,y_score))\n",
    "        print(\"Cohen kappa score : \", cohen_kappa_score(Y_test, y_score))\n",
    "        print(confusion_matrix(Y_test,y_score))  \n",
    "        print(classification_report(Y_test,y_score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"result_file.csv\", encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
